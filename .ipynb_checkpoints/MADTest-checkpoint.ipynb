{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c61ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate #用于 PromptTemplate 为字符串提示创建模板\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate #for multiple prompt merging\n",
    "\n",
    "#base class of all prompt generators, provide single prompt given arguments\n",
    "class PromptGenerator:\n",
    "    def __init__(self, promptFString):\n",
    "        self.prompt_template = PromptTemplate.from_template(\n",
    "            promptFString\n",
    "            #Sample: \"Tell me a {adjective} joke about {content}.\"\n",
    "        )\n",
    "    \n",
    "    def generatePrompt(self,**kwargs):\n",
    "        formatted_prompt = self.prompt_template.format(**kwargs)\n",
    "        return formatted_prompt\n",
    "\n",
    "\n",
    "#prompt generator for MAD situation:\n",
    "class MADPromptGenerator:\n",
    "    def __init__(self, prePromptGuide, postPromptGuide, numOfAgents):\n",
    "        self.prePromptGuide = PromptTemplate.from_template( prePromptGuide)\n",
    "        self.postPromptGuide = PromptTemplate.from_template(postPromptGuide)\n",
    "        self.numOfAgents = numOfAgents\n",
    "        self.angentsAnsGuide = PromptTemplate.from_template(\"\\n\\n\".join( [f\" One agent response:{{example{index}}}\" for index in range(numOfAgents)]))\n",
    "\n",
    "    def generatePrompt(self, prevAgentsInputs, currentAgentIndex,currentRound, preInputs=None,postInputs=None):\n",
    "        if preInputs !=None:\n",
    "            prePrompt = self.prePromptGuide.format(preInputs)\n",
    "        else:\n",
    "            prePrompt =  self.prePromptGuide.format()\n",
    "        \n",
    "        if postInputs != None:\n",
    "            postPrompt = self.postPromptGuide.format(postInputs)\n",
    "        else:\n",
    "            postPrompt = self.postPromptGuide.format()\n",
    "        \n",
    "        \n",
    "        fullPrompt = prePrompt + \"\\n \\n\"\n",
    "        for i in range(currentRound):\n",
    "            currentAgentInput = prevAgentsInputs[i][\"example{}\".format(currentAgentIndex)]\n",
    "            fullPrompt = fullPrompt +  f\" {currentAgentInput}\" + \"\\n\\n\"\n",
    "            prevAgentsInputs[i][\"example{}\".format(currentAgentIndex)] = \" \"\n",
    "            currentRoundAgentsContext = self.angentsAnsGuide.format(**(prevAgentsInputs[i]))\n",
    "            fullPrompt = fullPrompt + \"These are the recent/updated opinions from other agents:\"+ currentRoundAgentsContext + \"\\n \\n\"\n",
    "            prevAgentsInputs[i][\"example{}\".format(currentAgentIndex)] = currentAgentInput\n",
    "        \n",
    "        fullPrompt += postPrompt\n",
    "\n",
    "        return fullPrompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6cfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return type definition\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MathAns(BaseModel):\n",
    "    thinkingProcess: str = Field(description=\"thinking process which leads to the answer\")\n",
    "    answer: float = Field(description=\"Final Answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea96ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser, RetryWithErrorOutputParser\n",
    "\n",
    "import time\n",
    "\n",
    "openaiApiKey = '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'\n",
    "model_name = \"gpt-3.5-turbo\"# \"text-davinci-003\"\n",
    "\n",
    "class ProcessHandler:\n",
    "    def __init__(self,promptFString):\n",
    "        self.pG = PromptGenerator(promptFString)\n",
    "        self.llm = OpenAI(temperature=0.5, openai_api_key=openaiApiKey,model_name=model_name)\n",
    "    \n",
    "    def generateAnswer(self, questionPromptString):\n",
    "        formatedQuestion = self.pG.generatePrompt(questionPromptString)\n",
    "        return self.llm(formatedQuestion)\n",
    "    \n",
    "class MADProcessHandler:\n",
    "    def __init__(self,nrounds,nAgents, prePromptString, postPromptString, parser):\n",
    "        self.pG = MADPromptGenerator(prePromptString,postPromptString,nAgents)\n",
    "        self.nrounds = nrounds\n",
    "        self.llm = OpenAI(temperature=0.5, openai_api_key=openaiApiKey,model_name=model_name)\n",
    "        self.answersRecords = []\n",
    "        self.nAgents = nAgents\n",
    "        self.parser = parser\n",
    "\n",
    "    def generateAnswer(self, questionSting, prePromptString=None, postPromptString=None):\n",
    "        self.answersRecords.clear()\n",
    "        if prePromptString != None:\n",
    "            questionSting += prePromptString\n",
    "        for i in range(self.nrounds):\n",
    "            self.answersRecords.append({})\n",
    "            for j in range(self.nAgents):\n",
    "                prompt = questionSting\n",
    "                if i !=0:\n",
    "                    print(i)\n",
    "                    prompt = prompt + self.pG.generatePrompt(self.answersRecords, j,i)\n",
    "                \n",
    "                print(\"round{}\".format(i), \"agent{} prompt: \\n\".format(j),prompt)\n",
    "                answer = self.llm(prompt)\n",
    "                print(\"round{}\".format(i), \"agent{} answer: \\n\".format(j),answer)\n",
    "                time.sleep(30)\n",
    "                self.answersRecords[i][\"example{}\".format(j)] = answer\n",
    "        \n",
    "        prompt = questionSting+\"\\n\\n\" + \"The following paragraphs are previous answers given by other agents for your reference \\n\\n\"\n",
    "        for j in range(self.nAgents):\n",
    "            prompt = prompt+ \"agent{}'s answer:\\n\".format(j)+self.answersRecords[-1][\"example{}\".format(j)]+\"\\n\\n\"\n",
    "        prompt = prompt + \"Given the answers from other agents, please draw a final conclusion. Please Think Step by Step. Make sure to state your answer at the end of the response.\"\n",
    "\n",
    "        prompt = prompt+\"\\n\"+parser.get_format_instructions()\n",
    "        answer = self.llm(prompt)\n",
    "        \n",
    "        answer = self.parser.parse(answer)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad047a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30477\\anaconda3\\Lib\\site-packages\\langchain\\llms\\openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\30477\\anaconda3\\Lib\\site-packages\\langchain\\llms\\openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round0 agent0 prompt: \n",
      " What is the result of (18)+(14)*(-30)+(24)-(-10)*(24)+(14)*(28)/(-9)?Please Think Step by Step.\n",
      "round0 agent0 answer: \n",
      " To solve this expression step by step, we will follow the order of operations (PEMDAS/BODMAS):\n",
      "\n",
      "1. First, we will perform the multiplication and division from left to right:\n",
      "   (14)*(-30) = -420\n",
      "   (-10)*(24) = -240\n",
      "   (14)*(28) = 392\n",
      "   (392)/(-9) = -43.5556 (rounded to 4 decimal places)\n",
      "\n",
      "2. Now, we can rewrite the expression with the above calculations:\n",
      "   (18) + (-420) + (24) - (-240) + (-43.5556)\n",
      "\n",
      "3. Next, we will simplify the subtraction of a negative number:\n",
      "   - (-240) = +240\n",
      "\n",
      "4. Now, we can rewrite the expression with the above calculations:\n",
      "   (18) + (-420) + (24) + 240 + (-43.5556)\n",
      "\n",
      "5. Finally, we can add all the numbers together:\n",
      "   18 + (-420) + 24 + 240 + (-43.5556) = -181.5556\n",
      "\n",
      "Therefore, the result of the expression (18)+(14)*(-30)+(24)-(-10)*(24)+(14)*(28)/(-9) is approximately -181.5556.\n",
      "round0 agent1 prompt: \n",
      " What is the result of (18)+(14)*(-30)+(24)-(-10)*(24)+(14)*(28)/(-9)?Please Think Step by Step.\n",
      "round0 agent1 answer: \n",
      " To solve this expression step by step, we will follow the order of operations (PEMDAS).\n",
      "\n",
      "First, we need to simplify the multiplication and division within parentheses:\n",
      "\n",
      "(18) + (14)*(-30) + (24) - (-10)*(24) + (14)*(28)/(-9)\n",
      "= 18 + (-420) + 24 - (-240) + (-392)/(-9)\n",
      "\n",
      "Next, we simplify the subtraction of negative numbers:\n",
      "\n",
      "= 18 + (-420) + 24 + 240 + (-392)/(-9)\n",
      "\n",
      "Then, we perform the multiplication and division:\n",
      "\n",
      "= 18 + (-420) + 24 + 240 - 392/(-9)\n",
      "= 18 + (-420) + 24 + 240 + 392/9\n",
      "\n",
      "Now, we simplify the addition and subtraction:\n",
      "\n",
      "= -378 + 264 + 240 + 392/9\n",
      "\n",
      "Finally, we compute the division:\n",
      "\n",
      "= -378 + 264 + 240 + 43.55\n",
      "= 169.55\n",
      "\n",
      "Therefore, the result of the expression (18)+(14)*(-30)+(24)-(-10)*(24)+(14)*(28)/(-9) is approximately 169.55.\n",
      "Final Answer: -181.5556 Ground truth: -181.55555555555554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain.output_parsers import PydanticOutputParser, RetryWithErrorOutputParser\n",
    "\n",
    "agents = 2\n",
    "rounds = 1\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=MathAns)\n",
    "ph = MADProcessHandler(rounds,agents,\n",
    "     \" Make sure to state your answer at the end of the response.\"\n",
    "     ,\"Use these opinions carefully as additional advice, can you provide an updated answer? Make sure to state your answer at the end of the response.\",\n",
    "    parser)\n",
    "\n",
    "a, b, c, d, e, f, g, h, i = np.random.randint(-30, 30, size=9)\n",
    "\n",
    "\n",
    "answer = (a) + (b) * (c) + (d) - (e) * (f)+ (g)*(h)/(i)\n",
    "question_prompt = \"What is the result of ({})+({})*({})+({})-({})*({})+({})*({})/({})?Please Think Step by Step.\".format(a, b, c, d, e, f,g,h,i)\n",
    "\n",
    "print(\"Final Answer:\",(ph.generateAnswer(question_prompt)).answer,\"Ground truth:\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The problem\n",
    "\n",
    "#round 1 current agent answer\n",
    "#other agent also here so reponse； ...\n",
    "#one agent resonse: other agent answer\n",
    "...\n",
    "\n",
    "#round 2 current agent answer\n",
    "...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

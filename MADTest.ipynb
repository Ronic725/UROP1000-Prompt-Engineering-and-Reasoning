{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98cdfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate #用于 PromptTemplate 为字符串提示创建模板\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate #for multiple prompt merging\n",
    "\n",
    "#base class of all prompt generators, provide single prompt given arguments\n",
    "class PromptGenerator:\n",
    "    def __init__(self, promptFString):\n",
    "        self.prompt_template = PromptTemplate.from_template(\n",
    "            promptFString\n",
    "            #Sample: \"Tell me a {adjective} joke about {content}.\"\n",
    "        )\n",
    "    \n",
    "    def generatePrompt(self,**kwargs):\n",
    "        formatted_prompt = self.prompt_template.format(**kwargs)\n",
    "        return formatted_prompt\n",
    "\n",
    "\n",
    "#prompt generator for MAD situation:\n",
    "class MADPromptGenerator:\n",
    "    def __init__(self, prePromptGuide, postPromptGuide, numOfAgents):\n",
    "        self.prePromptGuide = PromptTemplate.from_template( prePromptGuide)\n",
    "        self.postPromptGuide = PromptTemplate.from_template(postPromptGuide)\n",
    "        self.numOfAgents = numOfAgents\n",
    "        self.angentsAnsGuide = PromptTemplate.from_template(\"\\n\\n\".join( [f\" One agent response:{{example{index}}}\" for index in range(numOfAgents)]))\n",
    "\n",
    "    def generatePrompt(self, prevAgentsInputs, currentAgentIndex,currentRound, preInputs=None,postInputs=None):\n",
    "        if preInputs !=None:\n",
    "            prePrompt = self.prePromptGuide.format(preInputs)\n",
    "        else:\n",
    "            prePrompt =  self.prePromptGuide.format()\n",
    "        \n",
    "        if postInputs != None:\n",
    "            postPrompt = self.postPromptGuide.format(postInputs)\n",
    "        else:\n",
    "            postPrompt = self.postPromptGuide.format()\n",
    "        \n",
    "        \n",
    "        fullPrompt = prePrompt + \"\\n \\n\"\n",
    "        for i in range(currentRound):\n",
    "            currentAgentInput = prevAgentsInputs[i][currentAgentIndex]\n",
    "            fullPrompt = fullPrompt +  f\"Your Answer: {currentAgentInput}\" + \"\\n\\n\"\n",
    "            prevAgentsInputs[i][currentAgentIndex] = \" \"\n",
    "            currentRoundAgentsContext = self.angentsAnsGuide.format(*(prevAgentsInputs[i]))\n",
    "            fullPrompt = fullPrompt + \"These are the recent/updated opinions from other agents:\"+ currentRoundAgentsContext + \"\\n \\n\"\n",
    "            prevAgentsInputs[i][currentAgentIndex] = currentAgentInput\n",
    "        \n",
    "        fullPrompt += postPrompt\n",
    "\n",
    "        return fullPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc1af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PromptGenerators\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "openaiApiKey = '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'\n",
    "\n",
    "class ProcessHandler:\n",
    "    def __init__(self,promptFString):\n",
    "        self.pG = PromptGenerators.PromptGenerator(promptFString)\n",
    "        self.llm = OpenAI(temperature=0.5, openai_api_key=openaiApiKey)\n",
    "    \n",
    "    def generateAnswer(self, questionPromptString):\n",
    "        formatedQuestion = self.pG.generatePrompt(questionPromptString)\n",
    "        return self.llm(formatedQuestion)\n",
    "    \n",
    "class MADProcessHandler:\n",
    "    def __init__(self,nrounds,nAgents, prePromptString, postPromptString):\n",
    "        self.pG = PromptGenerators.MADPromptGenerator(prePromptString,postPromptString,nAgents)\n",
    "        self.nrounds = nrounds\n",
    "        self.llm = OpenAI(temperature=0.5, openai_api_key=openaiApiKey)\n",
    "        self.answersRecords = []\n",
    "        self.nAgents = nAgents\n",
    "\n",
    "    def generateAnswer(self, questionSting, prePromptString=None, postPromptString=None):\n",
    "        self.answersRecords.clear()\n",
    "        if prePromptString != None:\n",
    "            questionSting += prePromptString\n",
    "        for i in range(self.nrounds):\n",
    "            self.answersRecords.append([])\n",
    "            for j in range(self.nAgents):\n",
    "                if i !=0:\n",
    "                    print(i)\n",
    "                    prompt = self.pG.generatePrompt(self.answersRecords, j,i)\n",
    "                else:\n",
    "                    prompt = questionSting\n",
    "                print(\"round{}\".format(i), \"agent{} prompt: \\n\".format(j),prompt)\n",
    "                answer = self.llm(prompt)\n",
    "                self.answersRecords[i].append(answer)\n",
    "        return self.answersRecords[self.nrounds-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed9a253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round0 agent0 prompt: \n",
      " What is the result of 6+13*13+23-19*19?\n",
      "round0 agent1 prompt: \n",
      " What is the result of 6+13*13+23-19*19?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PromptTemplate.format() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m answer \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;241m*\u001b[39m c \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m-\u001b[39m e \u001b[38;5;241m*\u001b[39m f\n\u001b[0;32m     11\u001b[0m question_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the result of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m+\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m+\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(a, b, c, d, e, f)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(ph\u001b[38;5;241m.\u001b[39mgenerateAnswer(question_prompt))\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mMADProcessHandler.generateAnswer\u001b[1;34m(self, questionSting, prePromptString, postPromptString)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnAgents):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 32\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpG\u001b[38;5;241m.\u001b[39mgeneratePrompt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswersRecords, j,i)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m questionSting\n",
      "File \u001b[1;32m~\\GitRepos\\UROP1000-Prompt-Engineering-and-Reasoning\\PromptGenerators.py:42\u001b[0m, in \u001b[0;36mMADPromptGenerator.generatePrompt\u001b[1;34m(self, prevAgentsInputs, currentAgentIndex, currentRound, preInputs, postInputs)\u001b[0m\n\u001b[0;32m     40\u001b[0m fullPrompt \u001b[38;5;241m=\u001b[39m fullPrompt \u001b[38;5;241m+\u001b[39m  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrentAgentInput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m prevAgentsInputs[i][currentAgentIndex] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 42\u001b[0m currentRoundAgentsContext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangentsAnsGuide\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m(prevAgentsInputs[i]))\n\u001b[0;32m     43\u001b[0m fullPrompt \u001b[38;5;241m=\u001b[39m fullPrompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThese are the recent/updated opinions from other agents:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m currentRoundAgentsContext \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m prevAgentsInputs[i][currentAgentIndex] \u001b[38;5;241m=\u001b[39m currentAgentInput\n",
      "\u001b[1;31mTypeError\u001b[0m: PromptTemplate.format() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "agents = 2\n",
    "rounds = 3\n",
    "ph = MADProcessHandler(rounds,agents,\n",
    "     \"Make sure to state your answer at the end of the response.\"\n",
    "     ,\"Use these opinions carefully as additional advice, can you provide an updated answer? Make sure to state your answer at the end of the response.\")\n",
    "\n",
    "a, b, c, d, e, f = np.random.randint(0, 30, size=6)\n",
    "\n",
    "answer = a + b * c + d - e * f\n",
    "question_prompt = \"What is the result of {}+{}*{}+{}-{}*{}?\".format(a, b, c, d, e, f)\n",
    "print(ph.generateAnswer(question_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389f35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
